{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### YouTube API Data Extraction with Python ###################\n",
    "############################# Author: Tyler Blair #############################\n",
    "\n",
    "# This script will pull data from YouTube using their APIs. To do this,\n",
    "# you will have to set up API credentials with Google, which can be easily\n",
    "# done at console.developers.google.com\n",
    "\n",
    "# Additionally, this script pulls the YouTube API key from your system's\n",
    "# environmental variables. If you are unfamiliar with how to do this, I\n",
    "# have included the steps in the README.md file on my GitHub (tblair7)\n",
    "\n",
    "import os\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "from datetime import datetime, time, timedelta, tzinfo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import google.oauth2.credentials\n",
    "\n",
    "import google_auth_oauthlib.flow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "\n",
    "##### you'll need to have already set your API key as an environmental ######\n",
    "##### variable before this point. If you haven't/don't want to do so   ######\n",
    "##### you can simply set it explicitly here:\n",
    "# api_key = ['your key']\n",
    "api_key = os.environ.get('YT_API_KEY')\n",
    "\n",
    "################### only parameters you should need to set ###################\n",
    "# documentation of parameters you are able to use for playlistItems\n",
    "# https://developers.google.com/youtube/v3/docs/playlistItems#properties\n",
    "\n",
    "playlistId = 'PLJpYtEF3No5Nq0GqRHb1-HYvFYwXwk8JM' # ID of the whatever api type you're utilizing\n",
    "playlistIdentifier = 'Test' # identifier for saving purposes\n",
    "maxResults = 3 # 0-250, though I've set 0 to mean no maximum so I can use it for my playlist\n",
    "\n",
    "api_params_playlist = 'snippet, contentDetails' # e.g., 'id, contentDetails, statistics' as a string\n",
    "api_params_videos = \"id, contentDetails, statistics, snippet\" # parameters I wish to retrieve from my playlist in the end\n",
    "\n",
    "# these are the column headers that are selected from the playlistItems df\n",
    "params_playlist = 'videoId', 'videoPublishedAt', 'publishedAt', 'title'\n",
    "params_playlist_rename = 'id', 'dateUploaded', 'dateFound', 'title'\n",
    "\n",
    "# these are the column headers that are selected from the videos dataframe\n",
    "params_videos = 'id','channelId','viewCount','likeCount','dislikeCount', 'duration'\n",
    "params_videos_rename = 'id', 'channelID','views', 'likes', 'dislikes', 'duration_secs'\n",
    "\n",
    "\n",
    "################################## Constants #################################\n",
    "\n",
    "\n",
    "url_playlist = \"https://www.googleapis.com/youtube/v3/playlistItems\"\n",
    "url_videos = \"https://www.googleapis.com/youtube/v3/videos\"\n",
    "\n",
    "times = ['H','M','S']\n",
    "s_conv = [3600,60,1]\n",
    "\n",
    "################################## Functions ##################################\n",
    "\n",
    "def gen_params(ID, api_params_videos, api_key):\n",
    "    parameters = {\"part\": api_params_videos,\n",
    "                  \"id\": ID,\n",
    "                  \"key\": api_key}\n",
    "    return parameters\n",
    "\n",
    "def pull_YT_data(url, parameters):\n",
    "    page = requests.get(url = url_videos,\n",
    "                        params = parameters)\n",
    "    j_results = json.loads(page.text)\n",
    "    df = pd.io.json.json_normalize(j_results['items'])\n",
    "    df.columns = df.columns.map(lambda x: x.split('.')[-1])\n",
    "    return df\n",
    "\n",
    "\n",
    "def song_length(duration,times,s_conv):\n",
    "    song_time = 0\n",
    "    \n",
    "    for i in range(len(times)):\n",
    "        my_regex = r'(\\d.?' + times[i] + ')'\n",
    "        pattern = re.search(my_regex, duration)\n",
    "        if pattern:\n",
    "            span_start = pattern.span(1)[0]\n",
    "            span_end = pattern.span(1)[1]\n",
    "            value = duration[span_start:span_end-1]\n",
    "            #print(c[span_start:span_end])\n",
    "            song_time = song_time + int(value)*s_conv[i]        \n",
    "        else:\n",
    "            None       \n",
    "    return song_time\n",
    "\n",
    "def date_parse(date):\n",
    "    date = date[0:9] + '-' + date[11:18]\n",
    "    date_conv = datetime.strptime(date, '%Y-%m-%d-%H:%M:%S')# T %H%M%S.%f Z')\n",
    "    #dateee = datetime.strptime(a[11:18],'%H:%M:%S')\n",
    "    return(date_conv)\n",
    "\n",
    "\n",
    "def time_diff_days(time1, time2):\n",
    "    timeDelta = (time1 - time2)\n",
    "    a = re.search(r'\\d*? ', str(timeDelta))\n",
    "    days_span_start = a.span(0)[0]\n",
    "    days_span_end = a.span(0)[1]\n",
    "    days = int(str(timeDelta)[days_span_start:days_span_end])\n",
    "    return(days)\n",
    "\n",
    "############################### Playlist API Calls ###############################\n",
    "\n",
    "# sets the parameters for the API request\n",
    "parameters = {\"part\": api_params_playlist,\n",
    "              \"playlistId\": playlistId,\n",
    "              \"key\": api_key}\n",
    "\n",
    "if maxResults == 0:\n",
    "    print('No maximum number of results returned')\n",
    "else:\n",
    "    parameters.update(dict(maxResults = maxResults))\n",
    "\n",
    "\n",
    "\n",
    "# pulls the data from YT and puts it in a usable format\n",
    "page = requests.get(url = url_playlist,\n",
    "                    params = parameters) # pulls the data\n",
    "j_results = json.loads(page.text) # make somewhat readable\n",
    "df = pd.io.json.json_normalize(j_results['items']) # formatted table, lots of redundant info\n",
    "df.columns = df.columns.map(lambda x: x.split('.')[-1])\n",
    "\n",
    "# truncates the data based on the params_playlist input from the beginning\n",
    "data_playlist = df.loc[:, df.columns.isin(list(params_playlist))]\n",
    "data_playlist = data_playlist.T.drop_duplicates(keep='first').T # drop_duplicates works on rows, so transpose, select row, transpose back\n",
    "data_playlist.columns = list(params_playlist_rename) # assigns column names\n",
    "\n",
    "\n",
    "for i in range(length):\n",
    "    data_playlist.dateUploaded.iloc[i] = date_parse(data_playlist.dateUploaded.iloc[i])\n",
    "    data_playlist.dateFound.iloc[i] = date_parse(data_playlist.dateFound.iloc[i])\n",
    "    data_playlist.discoveryTime = (data_playlist.dateFound.iloc[i] - data_playlist.dateUploaded.iloc[i])\n",
    "\n",
    "#################  Videos API requests and data manipulation #################\n",
    "\n",
    "\n",
    "#length = np.arange(data_playlist.shape[0])\n",
    "length = len(data_playlist)\n",
    "\n",
    "data_videos_full = pd.DataFrame([])\n",
    "\n",
    "for i in range(length):\n",
    "    parameters_vids = gen_params(data_playlist.id[i], api_params_videos, api_key)\n",
    "    df = pull_YT_data(url_videos,parameters_vids)\n",
    "    data_videos = df.loc[:, df.columns.isin(list(params_videos))]\n",
    "    data_videos = data_videos.T.drop_duplicates(keep='first').T\n",
    "    #data_videos.duration = song_length(data_videos.duration,times,s_conv)\n",
    "    data_videos_full = data_videos_full.append(data_videos)\n",
    "    data_videos_full.duration.iloc[i] = song_length(data_videos_full.duration.iloc[i],times,s_conv)\n",
    "\n",
    "data_videos_full = data_videos_full[['id','channelId','viewCount','likeCount','dislikeCount','duration']]\n",
    "data_videos_full.columns = list(params_videos_rename)\n",
    "\n",
    "full_data = pd.merge(data_playlist,data_videos_full, on='id', how='outer')\n",
    "full_data = full_data[['id','title','channelID','views','likes','dislikes','duration_secs','dateUploaded','dateFound']]\n",
    "full_data = full_data.reindex(columns = np.append(full_data.columns.values,'discoveryTime_days'))\n",
    "\n",
    "days = np.zeros(length,dtype=int)\n",
    "\n",
    "for i in range(length):\n",
    "    days[i] = time_diff_days(data_playlist.dateFound.iloc[i], data_playlist.dateUploaded.iloc[i])\n",
    "\n",
    "full_data.discoveryTime_days = days\n",
    "\n",
    "# saves the data_playlist structure as a .csv with a name dictated by the playlistIdentifier variable and the time\n",
    "time = datetime.now().strftime('_%Y_%m_%d')\n",
    "name = playlistIdentifier + time\n",
    "f = open('%s.csv' % name, 'w')\n",
    "full_data.to_csv(f.name)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
